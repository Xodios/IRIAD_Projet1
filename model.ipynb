{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's first import our data:p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"Data_sets.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>معدل الفصل الأول</th>\n",
       "      <th>معدل الفصل الثاني</th>\n",
       "      <th>معدل الفصل الثالث</th>\n",
       "      <th>معدل شهادة</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>426.000000</td>\n",
       "      <td>426.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>418.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.514390</td>\n",
       "      <td>12.378521</td>\n",
       "      <td>12.705975</td>\n",
       "      <td>12.382440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.496386</td>\n",
       "      <td>2.657466</td>\n",
       "      <td>2.653799</td>\n",
       "      <td>2.121872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.700000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.947500</td>\n",
       "      <td>10.230000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>11.725000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>11.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.340000</td>\n",
       "      <td>14.620000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>13.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18.470000</td>\n",
       "      <td>18.520000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>18.760000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       معدل الفصل الأول  معدل الفصل الثاني  معدل الفصل الثالث  معدل شهادة \n",
       "count        426.000000         426.000000         400.000000   418.000000\n",
       "mean          12.514390          12.378521          12.705975    12.382440\n",
       "std            2.496386           2.657466           2.653799     2.121872\n",
       "min            7.700000           8.000000           6.000000     9.000000\n",
       "25%           10.947500          10.230000          11.000000    10.720000\n",
       "50%           12.000000          11.725000          12.000000    11.965000\n",
       "75%           14.340000          14.620000          15.000000    13.800000\n",
       "max           18.470000          18.520000          19.000000    18.760000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "معدل الفصل الأول      0\n",
       "معدل الفصل الثاني     0\n",
       "معدل الفصل الثالث    26\n",
       "معدل شهادة            8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_missing = data.isna().sum()\n",
    "num_missing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will first work without the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>معدل الفصل الأول</th>\n",
       "      <th>معدل الفصل الثاني</th>\n",
       "      <th>معدل الفصل الثالث</th>\n",
       "      <th>معدل شهادة</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.75</td>\n",
       "      <td>9.57</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.50</td>\n",
       "      <td>16.07</td>\n",
       "      <td>16.11</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>15.41</td>\n",
       "      <td>16.32</td>\n",
       "      <td>17.57</td>\n",
       "      <td>14.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>13.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>12.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>14.70</td>\n",
       "      <td>14.65</td>\n",
       "      <td>14.40</td>\n",
       "      <td>14.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>11.50</td>\n",
       "      <td>12.50</td>\n",
       "      <td>12.50</td>\n",
       "      <td>11.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>11.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>396 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     معدل الفصل الأول  معدل الفصل الثاني  معدل الفصل الثالث  معدل شهادة \n",
       "1               10.75               9.57              10.00        10.84\n",
       "2                9.00               8.00               6.00        13.00\n",
       "3                9.00               8.00               9.00        10.00\n",
       "4               15.50              16.07              16.11        15.00\n",
       "5               10.00              10.00              10.00        10.11\n",
       "..                ...                ...                ...          ...\n",
       "421             15.41              16.32              17.57        14.95\n",
       "422             13.00              13.00              13.00        12.95\n",
       "423             14.70              14.65              14.40        14.47\n",
       "424             11.50              12.50              12.50        11.44\n",
       "425             11.00              12.00              12.00        11.00\n",
       "\n",
       "[396 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_without_null = data.dropna()\n",
    "data_without_null"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR REGRESSION ARC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's make our simple regression model to begin with :))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_without_null[['معدل الفصل الأول', 'معدل الفصل الثاني', 'معدل الفصل الثالث']]\n",
    "Y = data_without_null['معدل شهادة ']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on test set = 79.35%\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_test)\n",
    "score = model.score(X_test, Y_test)\n",
    "print(\"Model accuracy on test set = {:.2f}%\".format(score*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tbh Idk why I'm using score..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do some cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.63335052 0.69489829 0.63051206 0.71816201 0.76509215]\n",
      "Mean score: 0.6884030072103919\n"
     ]
    }
   ],
   "source": [
    "model_cv = LinearRegression()\n",
    "scores = cross_val_score(model_cv, X, Y, cv=5)\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean score:\", scores.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yep it's very bad so far"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's be smart and use MSE or RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation RMSE scores: [1.02286033 1.34536992 1.04109409 1.00572594 1.0355308 ]\n",
      "Mean RMSE score: 1.0901162155250752\n"
     ]
    }
   ],
   "source": [
    "scores = -1 * cross_val_score(model_cv, X, Y, cv=5, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(scores)\n",
    "print(\"Cross-validation RMSE scores:\", rmse_scores)\n",
    "print(\"Mean RMSE score:\", rmse_scores.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation RMSE scores: [1.09321431 0.99303757 1.27905666 1.35849361 1.15344964 0.93816241\n",
      " 1.00335544 1.00940325 1.02433499 1.05907243]\n",
      "Mean RMSE score: 1.0911580313056102\n"
     ]
    }
   ],
   "source": [
    "scores = -1 * cross_val_score(model_cv, X, Y, cv=10, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(scores)\n",
    "print(\"Cross-validation RMSE scores:\", rmse_scores)\n",
    "print(\"Mean RMSE score:\", rmse_scores.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K=396 aka Leave one out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation RMSE scores: [2.45671724e-01 4.23020047e+00 4.42552216e-01 1.61670277e-01\n",
      " 4.88869745e-01 5.91700701e-01 9.42322804e-01 3.86136467e-02\n",
      " 1.44688722e+00 6.40137501e-01 3.97600159e-01 3.15741026e-01\n",
      " 3.09766807e-01 4.52089679e-01 5.56607423e-01 1.14690644e+00\n",
      " 1.09400244e+00 4.73311300e-01 1.03562983e+00 3.29874499e-01\n",
      " 1.20177537e+00 8.06890487e-01 1.21115953e-01 7.08640407e-03\n",
      " 2.87147083e-01 1.14994628e-01 5.06700009e-01 2.18710644e+00\n",
      " 9.96978546e-01 1.62515149e-01 7.72910972e-01 4.43046297e-01\n",
      " 1.19672052e+00 5.87119296e-01 6.30480940e-01 1.64935432e+00\n",
      " 1.05994966e+00 4.98158405e-01 2.98464785e-01 1.01163494e+00\n",
      " 1.58976754e+00 3.99206598e-01 1.64448887e+00 1.20422830e+00\n",
      " 2.66683029e-01 1.74742717e+00 6.34040129e-01 5.26004044e-01\n",
      " 5.80769856e-01 6.95348552e-01 1.41257860e+00 2.29194467e-01\n",
      " 7.84030835e-01 1.42478611e-01 4.42552216e-01 3.94953720e-01\n",
      " 4.56983263e-01 1.71411513e-01 1.58452794e+00 1.14686041e-01\n",
      " 1.62887153e+00 5.67981242e-01 5.59751147e-01 8.61354595e-01\n",
      " 1.06962068e+00 6.61470370e-01 3.55768003e-01 1.31613302e+00\n",
      " 1.59561331e+00 3.03214507e-01 1.36585322e+00 8.91400764e-01\n",
      " 2.27671454e+00 6.10444160e-02 3.26595910e-02 4.75277892e-01\n",
      " 7.51716708e-01 1.04303911e+00 9.00544525e-01 7.63132151e-01\n",
      " 2.74514827e-01 1.31613302e+00 3.82386265e-01 3.75009551e-01\n",
      " 6.09586220e-01 4.56983263e-01 1.06044418e+00 1.12407790e+00\n",
      " 7.43418623e-01 1.45345973e+00 5.58120851e-01 4.77303402e-01\n",
      " 2.27491329e-01 6.14486177e-01 4.77789166e-01 8.19494219e-01\n",
      " 1.33305951e+00 1.10133761e+00 8.65343768e-02 1.57623671e+00\n",
      " 2.39093889e+00 1.08310027e+00 1.00713128e+00 4.39239119e-01\n",
      " 4.04090369e-01 3.13200159e+00 1.64984339e+00 1.78915170e+00\n",
      " 2.68678449e-01 2.09992505e-01 5.96897133e-01 7.66427817e-01\n",
      " 8.50284966e-01 1.93590327e+00 1.09816633e+00 2.48683066e+00\n",
      " 2.00843937e+00 8.73447796e-01 1.43269845e+00 2.69528368e+00\n",
      " 6.58125236e-01 6.64288111e-01 8.20040528e-01 2.06878715e+00\n",
      " 6.73140386e-01 1.14712629e-01 4.53478173e-01 7.84746958e-01\n",
      " 2.85694186e-01 1.80739655e+00 9.39596322e-01 6.06298221e-01\n",
      " 1.29655591e+00 3.12270818e+00 7.67041019e-01 3.26783030e+00\n",
      " 1.28173327e+00 9.05939670e-01 1.49660301e+00 3.39209140e-01\n",
      " 2.81073510e-01 1.52884331e+00 1.15007171e+00 2.05512024e+00\n",
      " 1.92662614e+00 7.39227726e-01 1.49066065e+00 7.65580483e-01\n",
      " 6.27417123e-01 2.57861533e-02 3.52506456e-01 2.03799875e+00\n",
      " 1.81667283e+00 1.32431660e+00 1.12280879e+00 7.11461757e-01\n",
      " 1.49457963e+00 1.93228300e+00 8.72971464e-02 8.46425690e-01\n",
      " 3.16554638e-01 1.92460454e-01 9.53698715e-02 2.22591989e-01\n",
      " 6.45879915e-01 1.58589292e-01 2.10638482e+00 1.19088911e+00\n",
      " 6.26200347e-01 3.20554559e-01 1.03445299e+00 4.28667814e-01\n",
      " 1.00243694e+00 1.06055662e+00 5.06992976e-01 6.23502299e-04\n",
      " 2.32017160e+00 2.49530182e+00 1.05477602e+00 1.71783554e+00\n",
      " 9.12889107e-01 1.78131395e+00 9.99143724e-01 5.68036611e-02\n",
      " 2.54128619e+00 2.43944681e+00 1.44688722e+00 6.40137501e-01\n",
      " 3.97600159e-01 3.15741026e-01 3.09766807e-01 4.52089679e-01\n",
      " 5.56607423e-01 1.14690644e+00 1.09400244e+00 4.73311300e-01\n",
      " 1.03562983e+00 3.29874499e-01 1.20177537e+00 8.06890487e-01\n",
      " 1.21115953e-01 7.08640407e-03 2.87147083e-01 1.14994628e-01\n",
      " 5.06700009e-01 2.18710644e+00 9.96978546e-01 1.62515149e-01\n",
      " 7.72910972e-01 4.43046297e-01 1.19672052e+00 5.87119296e-01\n",
      " 6.30480940e-01 1.64935432e+00 1.05994966e+00 4.98158405e-01\n",
      " 2.98464785e-01 1.01163494e+00 1.58976754e+00 3.99206598e-01\n",
      " 1.64448887e+00 1.20422830e+00 2.66683029e-01 1.74742717e+00\n",
      " 6.34040129e-01 5.26004044e-01 5.80769856e-01 6.95348552e-01\n",
      " 1.41257860e+00 2.29194467e-01 7.84030835e-01 1.42478611e-01\n",
      " 4.42552216e-01 3.94953720e-01 4.56983263e-01 1.71411513e-01\n",
      " 1.58452794e+00 1.14686041e-01 1.62887153e+00 5.67981242e-01\n",
      " 5.59751147e-01 8.61354595e-01 1.06962068e+00 6.61470370e-01\n",
      " 3.55768003e-01 1.31613302e+00 1.59561331e+00 3.03214507e-01\n",
      " 1.36585322e+00 8.91400764e-01 2.27671454e+00 6.10444160e-02\n",
      " 3.26595910e-02 4.75277892e-01 7.51716708e-01 1.04303911e+00\n",
      " 9.00544525e-01 7.63132151e-01 2.74514827e-01 1.31613302e+00\n",
      " 3.82386265e-01 3.75009551e-01 6.09586220e-01 4.56983263e-01\n",
      " 1.06044418e+00 1.12407790e+00 7.43418623e-01 1.45345973e+00\n",
      " 5.58120851e-01 4.77303402e-01 2.27491329e-01 6.14486177e-01\n",
      " 4.77789166e-01 8.19494219e-01 1.33305951e+00 1.10133761e+00\n",
      " 8.65343768e-02 1.57623671e+00 2.39093889e+00 1.08310027e+00\n",
      " 1.00713128e+00 4.39239119e-01 4.04090369e-01 3.13200159e+00\n",
      " 1.64984339e+00 1.78915170e+00 2.68678449e-01 2.09992505e-01\n",
      " 5.96897133e-01 7.66427817e-01 8.50284966e-01 1.44688722e+00\n",
      " 6.40137501e-01 3.97600159e-01 3.15741026e-01 3.09766807e-01\n",
      " 4.52089679e-01 5.56607423e-01 1.14690644e+00 1.09400244e+00\n",
      " 4.73311300e-01 1.03562983e+00 3.29874499e-01 1.20177537e+00\n",
      " 8.06890487e-01 1.21115953e-01 7.08640407e-03 2.87147083e-01\n",
      " 1.14994628e-01 5.06700009e-01 2.18710644e+00 9.96978546e-01\n",
      " 1.62515149e-01 7.72910972e-01 4.43046297e-01 1.19672052e+00\n",
      " 5.87119296e-01 6.30480940e-01 1.64935432e+00 1.05994966e+00\n",
      " 4.98158405e-01 2.98464785e-01 1.01163494e+00 1.58976754e+00\n",
      " 3.99206598e-01 1.64448887e+00 1.20422830e+00 2.66683029e-01\n",
      " 1.74742717e+00 6.34040129e-01 5.26004044e-01 5.80769856e-01\n",
      " 6.95348552e-01 1.41257860e+00 2.29194467e-01 7.84030835e-01\n",
      " 1.42478611e-01 4.42552216e-01 3.94953720e-01 4.56983263e-01\n",
      " 1.71411513e-01 1.58452794e+00 1.14686041e-01 1.62887153e+00\n",
      " 5.67981242e-01 5.59751147e-01 8.61354595e-01 1.06962068e+00\n",
      " 6.61470370e-01 3.55768003e-01 1.31613302e+00 1.59561331e+00\n",
      " 3.03214507e-01 1.36585322e+00 8.91400764e-01 2.27671454e+00\n",
      " 6.10444160e-02 3.26595910e-02 4.75277892e-01 7.51716708e-01\n",
      " 1.04303911e+00 9.00544525e-01 7.63132151e-01 2.74514827e-01\n",
      " 1.31613302e+00 3.82386265e-01 3.75009551e-01 6.09586220e-01\n",
      " 4.56983263e-01 1.06044418e+00 1.12407790e+00 7.43418623e-01\n",
      " 1.45345973e+00 5.58120851e-01 4.77303402e-01 2.27491329e-01\n",
      " 6.14486177e-01 4.77789166e-01 8.19494219e-01 1.33305951e+00\n",
      " 1.10133761e+00 8.65343768e-02 1.57623671e+00 2.39093889e+00\n",
      " 1.08310027e+00 1.00713128e+00 4.39239119e-01 4.04090369e-01\n",
      " 3.13200159e+00 1.64984339e+00 1.78915170e+00 2.68678449e-01\n",
      " 2.09992505e-01 5.96897133e-01 7.66427817e-01 8.50284966e-01]\n",
      "Mean RMSE score: 0.8718733400796387\n"
     ]
    }
   ],
   "source": [
    "scores = -1 * cross_val_score(model_cv, X, Y, cv=396, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(scores)\n",
    "print(\"Cross-validation RMSE scores:\", rmse_scores)\n",
    "print(\"Mean RMSE score:\", rmse_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>396.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.871873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.654622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.398805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.695349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.196721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.230200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  396.000000\n",
       "mean     0.871873\n",
       "std      0.654622\n",
       "min      0.000624\n",
       "25%      0.398805\n",
       "50%      0.695349\n",
       "75%      1.196721\n",
       "max      4.230200"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rmse_scores).describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion(Linear regression)\n",
    "So sometimse the prediction is way off (it reached a difference of 4 points...) I think it's better if we use something else.\n",
    "Let's try XGboost my favorite"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGREGRESSOR ARC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation RMSE scores: [0.59358746 0.10564773 1.14788954 1.47758649 1.19628351 0.08248284\n",
      " 0.26147707 0.20847565 0.08782149 0.29073003]\n",
      "Mean RMSE score: 0.5451981808330427\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(objective='reg:squarederror', n_estimators=1000)\n",
    "scores = -1 * cross_val_score(model, X, Y, cv=10, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(scores)\n",
    "print(\"Cross-validation RMSE scores:\", rmse_scores)\n",
    "print(\"Mean RMSE score:\", rmse_scores.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already way better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation RMSE scores: [4.72660866e-01 2.85101128e+00 1.25414848e-01 9.99588013e-01\n",
      " 6.12055206e-02 1.35250828e+00 7.71933632e-01 1.28230835e+00\n",
      " 4.32243347e-04 1.63795471e-03 2.16636658e-04 9.36088562e-04\n",
      " 1.42250061e-04 1.08909607e-04 5.76782227e-05 1.76010132e-03\n",
      " 3.96614075e-04 3.47633362e-04 3.59485245e-01 2.24800110e-04\n",
      " 4.82559204e-05 9.20448303e-04 9.98916626e-04 4.14924622e-04\n",
      " 8.71276855e-05 2.36358643e-04 1.10321045e-03 1.11007690e-04\n",
      " 1.50436401e-03 5.88150024e-04 9.03701782e-05 4.80766296e-04\n",
      " 9.42459106e-04 2.63519287e-04 2.21519470e-04 7.09114075e-04\n",
      " 2.96401978e-05 8.03947449e-04 1.42143250e-03 1.68457031e-04\n",
      " 1.85298920e-03 1.33914948e-03 3.59930992e-01 1.05140686e-03\n",
      " 1.21559143e-03 1.16176605e-03 2.66830444e-03 2.26936340e-04\n",
      " 7.82165527e-04 1.66110039e-01 3.36456299e-04 1.51176453e-03\n",
      " 3.32353592e-01 2.66799927e-04 1.25414848e-01 1.09405518e-04\n",
      " 3.02314758e-04 6.75811768e-04 7.34710693e-05 7.38372803e-04\n",
      " 2.74238586e-04 9.08279419e-04 5.11436462e-04 4.89501953e-04\n",
      " 3.67027283e-03 3.37219238e-04 8.96949768e-04 1.66663170e-01\n",
      " 5.69992065e-04 1.64642334e-04 1.33228302e-03 1.96800232e-03\n",
      " 2.95867920e-04 6.02722168e-04 6.49795532e-04 1.85661316e-04\n",
      " 3.83783379e-01 4.51522827e-03 1.01806641e-03 1.82205200e-03\n",
      " 3.32494736e-01 1.66663170e-01 2.36801147e-03 1.20008755e+00\n",
      " 2.11291084e-01 3.02314758e-04 8.90960693e-04 1.01383209e-03\n",
      " 1.11427307e-04 2.67028809e-05 5.99365234e-04 1.11923218e-04\n",
      " 9.17594910e-01 4.85229492e-04 8.84628296e-05 7.82966614e-04\n",
      " 3.24249268e-05 3.08227539e-05 1.87778473e-03 1.49211884e-03\n",
      " 2.52990723e-04 6.17027283e-04 1.21612549e-04 1.03050232e-03\n",
      " 1.17383957e-01 3.31020355e-03 1.19837856e+00 7.59124756e-04\n",
      " 2.21061707e-04 9.90104675e-04 4.89044189e-05 3.54232788e-04\n",
      " 3.34226608e-01 2.41839695e+00 4.24550858e-01 1.99218655e+00\n",
      " 4.99378204e-01 1.23910389e+00 2.48469673e+00 5.71752907e+00\n",
      " 5.28154030e-01 8.60843658e-02 1.27977371e-01 8.19086075e-01\n",
      " 4.62176590e-01 6.88734970e-01 5.34729843e-01 1.79264378e+00\n",
      " 2.56757355e+00 8.08306808e-01 7.80175476e-01 1.13225365e+00\n",
      " 1.66968987e+00 5.53336807e+00 5.57403564e-02 3.27942753e+00\n",
      " 1.00112820e+00 1.89966774e-01 1.83044052e+00 1.67901974e+00\n",
      " 4.18108330e-01 1.24659157e+00 2.45824081e+00 2.51868973e-01\n",
      " 2.23938580e+00 2.27529526e-01 1.41457199e+00 6.67982101e-01\n",
      " 4.95402679e-01 6.48859024e-01 9.25686035e-01 1.76923431e+00\n",
      " 6.88982964e-01 1.61635696e+00 2.43306351e+00 3.35349083e-01\n",
      " 1.52156792e+00 2.52622162e+00 2.74713585e+00 3.61986542e-02\n",
      " 1.45368462e-01 8.47949982e-02 3.47213745e-02 1.00135422e+00\n",
      " 7.61360512e-01 9.97704506e-01 3.02405910e+00 1.61703854e+00\n",
      " 8.55397186e-01 1.04843132e+00 7.84639969e-01 2.33990253e+00\n",
      " 1.74803444e+00 1.43650181e+00 1.18602333e-01 8.00402565e-01\n",
      " 9.99897957e-01 2.16824772e+00 1.54020786e+00 1.53523159e+00\n",
      " 5.29941673e-01 1.93428993e+00 5.51826477e-01 1.40551567e-01\n",
      " 2.74886036e+00 2.43962955e+00 4.32243347e-04 1.63795471e-03\n",
      " 2.16636658e-04 9.36088562e-04 1.42250061e-04 1.08909607e-04\n",
      " 5.76782227e-05 1.76010132e-03 3.96614075e-04 3.47633362e-04\n",
      " 3.59485245e-01 2.24800110e-04 4.82559204e-05 9.20448303e-04\n",
      " 9.98916626e-04 4.14924622e-04 8.71276855e-05 2.36358643e-04\n",
      " 1.10321045e-03 1.11007690e-04 1.50436401e-03 5.88150024e-04\n",
      " 9.03701782e-05 4.80766296e-04 9.42459106e-04 2.63519287e-04\n",
      " 2.21519470e-04 7.09114075e-04 2.96401978e-05 8.03947449e-04\n",
      " 1.42143250e-03 1.68457031e-04 1.85298920e-03 1.33914948e-03\n",
      " 3.59930992e-01 1.05140686e-03 1.21559143e-03 1.16176605e-03\n",
      " 2.66830444e-03 2.26936340e-04 7.82165527e-04 1.66110039e-01\n",
      " 3.36456299e-04 1.51176453e-03 3.32353592e-01 2.66799927e-04\n",
      " 1.25414848e-01 1.09405518e-04 3.02314758e-04 6.75811768e-04\n",
      " 7.34710693e-05 7.38372803e-04 2.74238586e-04 9.08279419e-04\n",
      " 5.11436462e-04 4.89501953e-04 3.67027283e-03 3.37219238e-04\n",
      " 8.96949768e-04 1.66663170e-01 5.69992065e-04 1.64642334e-04\n",
      " 1.33228302e-03 1.96800232e-03 2.95867920e-04 6.02722168e-04\n",
      " 6.49795532e-04 1.85661316e-04 3.83783379e-01 4.51522827e-03\n",
      " 1.01806641e-03 1.82205200e-03 3.32494736e-01 1.66663170e-01\n",
      " 2.36801147e-03 1.20008755e+00 2.11291084e-01 3.02314758e-04\n",
      " 8.90960693e-04 1.01383209e-03 1.11427307e-04 2.67028809e-05\n",
      " 5.99365234e-04 1.11923218e-04 9.17594910e-01 4.85229492e-04\n",
      " 8.84628296e-05 7.82966614e-04 3.24249268e-05 3.08227539e-05\n",
      " 1.87778473e-03 1.49211884e-03 2.52990723e-04 6.17027283e-04\n",
      " 1.21612549e-04 1.03050232e-03 1.17383957e-01 3.31020355e-03\n",
      " 1.19837856e+00 7.59124756e-04 2.21061707e-04 9.90104675e-04\n",
      " 4.89044189e-05 3.54232788e-04 3.34226608e-01 4.32243347e-04\n",
      " 1.63795471e-03 2.16636658e-04 9.36088562e-04 1.42250061e-04\n",
      " 1.08909607e-04 5.76782227e-05 1.76010132e-03 3.96614075e-04\n",
      " 3.47633362e-04 3.59485245e-01 2.24800110e-04 4.82559204e-05\n",
      " 9.20448303e-04 9.98916626e-04 4.14924622e-04 8.71276855e-05\n",
      " 2.36358643e-04 1.10321045e-03 1.11007690e-04 1.50436401e-03\n",
      " 5.88150024e-04 9.03701782e-05 4.80766296e-04 9.42459106e-04\n",
      " 2.63519287e-04 2.21519470e-04 7.09114075e-04 2.96401978e-05\n",
      " 8.03947449e-04 1.42143250e-03 1.68457031e-04 1.85298920e-03\n",
      " 1.33914948e-03 3.59930992e-01 1.05140686e-03 1.21559143e-03\n",
      " 1.16176605e-03 2.66830444e-03 2.26936340e-04 7.82165527e-04\n",
      " 1.66110039e-01 3.36456299e-04 1.51176453e-03 3.32353592e-01\n",
      " 2.66799927e-04 1.25414848e-01 1.09405518e-04 3.02314758e-04\n",
      " 6.75811768e-04 7.34710693e-05 7.38372803e-04 2.74238586e-04\n",
      " 9.08279419e-04 5.11436462e-04 4.89501953e-04 3.67027283e-03\n",
      " 3.37219238e-04 8.96949768e-04 1.66663170e-01 5.69992065e-04\n",
      " 1.64642334e-04 1.33228302e-03 1.96800232e-03 2.95867920e-04\n",
      " 6.02722168e-04 6.49795532e-04 1.85661316e-04 3.83783379e-01\n",
      " 4.51522827e-03 1.01806641e-03 1.82205200e-03 3.32494736e-01\n",
      " 1.66663170e-01 2.36801147e-03 1.20008755e+00 2.11291084e-01\n",
      " 3.02314758e-04 8.90960693e-04 1.01383209e-03 1.11427307e-04\n",
      " 2.67028809e-05 5.99365234e-04 1.11923218e-04 9.17594910e-01\n",
      " 4.85229492e-04 8.84628296e-05 7.82966614e-04 3.24249268e-05\n",
      " 3.08227539e-05 1.87778473e-03 1.49211884e-03 2.52990723e-04\n",
      " 6.17027283e-04 1.21612549e-04 1.03050232e-03 1.17383957e-01\n",
      " 3.31020355e-03 1.19837856e+00 7.59124756e-04 2.21061707e-04\n",
      " 9.90104675e-04 4.89044189e-05 3.54232788e-04 3.34226608e-01]\n",
      "Mean RMSE score: 0.3122212680662521\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(objective='reg:squarederror', n_estimators=1000)\n",
    "scores = -1 * cross_val_score(model, X, Y, cv=396, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(scores)\n",
    "print(\"Cross-validation RMSE scores:\", rmse_scores)\n",
    "print(\"Mean RMSE score:\", rmse_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>396.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.312221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.723407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.195298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.717529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  396.000000\n",
       "mean     0.312221\n",
       "std      0.723407\n",
       "min      0.000027\n",
       "25%      0.000302\n",
       "50%      0.001006\n",
       "75%      0.195298\n",
       "max      5.717529"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rmse_scores).describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I really wanna know what did it scew up so badly....\n",
    "Time to do some research :3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1,   5,   7,  83, 106, 113, 115, 117, 118, 119, 127, 128, 131,\n",
       "        132, 133, 135, 136, 138, 139, 141, 142, 144, 146, 151, 153, 154,\n",
       "        156, 157, 158, 163, 166, 167, 169, 171, 172, 173, 177, 178, 179,\n",
       "        181, 184, 185, 261, 284, 366, 389], dtype=int64),)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(rmse_scores>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_indexes = list()\n",
    "for i in np.array(np.where(rmse_scores>1)[0]):\n",
    "    list_of_indexes.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>معدل الفصل الأول</th>\n",
       "      <th>معدل الفصل الثاني</th>\n",
       "      <th>معدل الفصل الثالث</th>\n",
       "      <th>معدل شهادة</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.81</td>\n",
       "      <td>9.48</td>\n",
       "      <td>10.22</td>\n",
       "      <td>11.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.30</td>\n",
       "      <td>9.50</td>\n",
       "      <td>9.00</td>\n",
       "      <td>10.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>11.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>11.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>14.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>15.50</td>\n",
       "      <td>15.50</td>\n",
       "      <td>15.50</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>16.25</td>\n",
       "      <td>16.65</td>\n",
       "      <td>17.75</td>\n",
       "      <td>14.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>15.04</td>\n",
       "      <td>14.91</td>\n",
       "      <td>16.39</td>\n",
       "      <td>15.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>17.07</td>\n",
       "      <td>17.14</td>\n",
       "      <td>16.71</td>\n",
       "      <td>18.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>14.71</td>\n",
       "      <td>15.00</td>\n",
       "      <td>14.64</td>\n",
       "      <td>13.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>17.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>17.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>17.68</td>\n",
       "      <td>17.90</td>\n",
       "      <td>17.84</td>\n",
       "      <td>17.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>17.10</td>\n",
       "      <td>17.08</td>\n",
       "      <td>16.93</td>\n",
       "      <td>12.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>13.28</td>\n",
       "      <td>13.51</td>\n",
       "      <td>14.38</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>13.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>14.50</td>\n",
       "      <td>14.92</td>\n",
       "      <td>14.80</td>\n",
       "      <td>15.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>14.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>12.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>15.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>16.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>13.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>12.85</td>\n",
       "      <td>13.04</td>\n",
       "      <td>13.25</td>\n",
       "      <td>14.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>15.40</td>\n",
       "      <td>15.63</td>\n",
       "      <td>16.38</td>\n",
       "      <td>13.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>17.38</td>\n",
       "      <td>17.66</td>\n",
       "      <td>17.00</td>\n",
       "      <td>17.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>13.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>14.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>12.13</td>\n",
       "      <td>11.50</td>\n",
       "      <td>13.12</td>\n",
       "      <td>10.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>12.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>10.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>13.51</td>\n",
       "      <td>13.62</td>\n",
       "      <td>14.65</td>\n",
       "      <td>13.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>11.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>12.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>13.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>10.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>10.55</td>\n",
       "      <td>10.60</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>12.76</td>\n",
       "      <td>13.13</td>\n",
       "      <td>13.23</td>\n",
       "      <td>12.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>9.99</td>\n",
       "      <td>10.32</td>\n",
       "      <td>10.42</td>\n",
       "      <td>9.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>10.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>9.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>11.53</td>\n",
       "      <td>12.08</td>\n",
       "      <td>13.11</td>\n",
       "      <td>9.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>13.00</td>\n",
       "      <td>10.76</td>\n",
       "      <td>13.00</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>12.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>9.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>11.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>12.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>11.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>11.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>11.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>11.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     معدل الفصل الأول  معدل الفصل الثاني  معدل الفصل الثالث  معدل شهادة \n",
       "2                9.00               8.00               6.00        13.00\n",
       "6                9.81               9.48              10.22        11.03\n",
       "8               10.30               9.50               9.00        10.24\n",
       "93              11.00              12.00              11.00        12.00\n",
       "116             11.00              12.00              11.00        10.00\n",
       "123             14.00              13.00              13.00        11.00\n",
       "125             15.50              15.50              15.50        17.00\n",
       "127             16.25              16.65              17.75        14.65\n",
       "128             15.04              14.91              16.39        15.86\n",
       "129             17.07              17.14              16.71        18.26\n",
       "137             14.71              15.00              14.64        13.26\n",
       "138             17.00              16.00              17.00        15.00\n",
       "141             17.00              17.00              17.00        15.00\n",
       "142             17.68              17.90              17.84        17.47\n",
       "143             17.10              17.08              16.93        12.54\n",
       "145             13.28              13.51              14.38        10.00\n",
       "146             13.00              14.00              14.00        12.00\n",
       "148             14.50              14.92              14.80        15.50\n",
       "149             14.00              13.00              14.00        12.80\n",
       "151             15.00              16.00              15.00        16.00\n",
       "152             16.00              15.00              16.00        13.43\n",
       "154             12.85              13.04              13.25        14.70\n",
       "156             15.40              15.63              16.38        13.26\n",
       "161             17.38              17.66              17.00        17.89\n",
       "163             13.00              14.00              13.00        14.37\n",
       "164             16.00              16.00              16.00        16.00\n",
       "166             12.13              11.50              13.12        10.65\n",
       "167             12.00              13.00              13.00        10.64\n",
       "168             13.51              13.62              14.65        13.47\n",
       "173             11.00              10.00              10.00        11.00\n",
       "177             12.00              11.00              12.00        13.80\n",
       "178             10.00              11.00              11.00         9.95\n",
       "180             10.55              10.60              11.00        11.42\n",
       "182             12.76              13.13              13.23        12.36\n",
       "184              9.99              10.32              10.42         9.79\n",
       "185             10.00               9.00              12.00         9.68\n",
       "189             11.53              12.08              13.11         9.73\n",
       "190             13.00              10.76              13.00        11.00\n",
       "191             12.00              11.00              12.00        10.00\n",
       "193              9.00              11.00              10.00         9.00\n",
       "196             11.00              11.00              12.00         9.00\n",
       "197             12.00              10.00              12.00         9.00\n",
       "282             11.00              12.00              11.00        12.00\n",
       "305             11.00              12.00              11.00        10.00\n",
       "396             11.00              12.00              11.00        12.00\n",
       "419             11.00              12.00              11.00        10.00"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_without_null.iloc[list_of_indexes]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already tell that some of them are weird \n",
    "I think we should make a model where he can find those weird "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = model.predict(data_without_null.iloc[list_of_indexes][['معدل الفصل الأول', 'معدل الفصل الثاني', 'معدل الفصل الثالث']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall it gives better results though there are some exceptions where the result is way off (5.71 point off ://)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation RMSE scores: [0.40264844 1.21018442 0.83485793 0.20971502 0.21405347]\n",
      "Mean RMSE score: 0.5742918558268314\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(objective='reg:squarederror', n_estimators=100000)\n",
    "scores = -1 * cross_val_score(model, X, Y, cv=5, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(scores)\n",
    "print(\"Cross-validation RMSE scores:\", rmse_scores)\n",
    "print(\"Mean RMSE score:\", rmse_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation RMSE scores: [0.59358746 0.10564773 1.14788954 1.47758649 1.19628351 0.08248284\n",
      " 0.26147707 0.20847565 0.08782149 0.29073003]\n",
      "Mean RMSE score: 0.5451981808330427\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(objective='reg:squarederror', n_estimators=100000)\n",
    "scores = -1 * cross_val_score(model, X, Y, cv=10, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(scores)\n",
    "print(\"Cross-validation RMSE scores:\", rmse_scores)\n",
    "print(\"Mean RMSE score:\", rmse_scores.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 1s 3ms/step - loss: 103.9318\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 89.5474\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 76.1822\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 64.2998\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 53.8291\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 44.5048\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 36.5604\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 29.6089\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 23.6350\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 18.4863\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 14.2577\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 10.8234\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 8.1149\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 6.0877\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.5859\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 3.5344\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.8253\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.3683\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.0726\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9134\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8088\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7602\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7323\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7201\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7137\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7105\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7083\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7076\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7071\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7071\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7063\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7061\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7057\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7051\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7055\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7040\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7048\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7039\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7034\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7023\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7023\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.7017\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.7020\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.7002\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6998\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.6991\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.6995\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6986\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6976\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ce03ad4f50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "NN_model.add(Dense(10, input_dim=3, activation='relu'))\n",
    "NN_model.add(Dense(1))\n",
    "NN_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "NN_model.fit(X_train, y_train, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n",
      "Test RMSE: 1.241\n"
     ]
    }
   ],
   "source": [
    "y_pred = NN_model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that great I need to change how much layers I need to put"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
